# Улучшение точности определения BPM

## Текущая ситуация

- Используется `librosa.beat.beat_track()` для определения BPM
- Точность: обычно ±1-2 BPM, иногда до ±3 BPM
- Сравнение: Moises.ai (https://studio.moises.ai/) использует обученные нейросети и может быть точнее

## Критичность разницы

Разница в 3 BPM (например, 123 vs 126) составляет около 2.4% - для бачаты это обычно **не критично**, но может быть заметно при синхронизации.

Обычно точность ±1-2 BPM считается хорошей для практического применения.

## Способы улучшения точности в librosa

### 1. Настройка параметров `beat_track()`

```python
# Более точные параметры
tempo, beats = librosa.beat.beat_track(
    y=y, 
    sr=sr,
    units='time',
    hop_length=512,  # Меньше = точнее, но медленнее
    start_bpm=120.0,  # Начальное предположение для бачаты
    std_bpm=1.0,     # Стандартное отклонение (ужесточить)
    trim=True        # Обрезка выбросов
)
```

**Параметры:**
- `hop_length`: меньшее значение = более точный анализ, но медленнее
- `start_bpm`: начальное предположение (для бачаты обычно 120-140)
- `std_bpm`: стандартное отклонение BPM (меньше = ужесточить поиск)
- `trim`: обрезка выбросов для более стабильного результата

### 2. Использование `tempogram` для более точного определения

```python
# Анализ tempogram (график темпа во времени)
tempo_frames = librosa.beat.tempo(y=y, sr=sr, aggregate=np.median)
tempo = librosa.tempo_frames_to_tempo(tempo_frames, sr=sr)
```

**Преимущества:**
- Анализирует темп во времени, а не только средний
- `aggregate=np.median` дает более стабильный результат

### 3. Комбинирование нескольких методов

```python
import numpy as np

# Метод 1: beat_track
tempo1, _ = librosa.beat.beat_track(y=y, sr=sr)

# Метод 2: tempogram
tempo2 = librosa.beat.tempo(y=y, sr=sr, aggregate=np.median)[0]

# Метод 3: onset detection + анализ интервалов
onsets = librosa.onset.onset_detect(y=y, sr=sr, units='time')
if len(onsets) > 1:
    intervals = np.diff(onsets[:20])  # Первые 20 интервалов
    tempo3 = 60.0 / np.median(intervals)
else:
    tempo3 = tempo1[0]

# Усредняем результаты (медиана более устойчива к выбросам)
final_tempo = np.median([tempo1[0], tempo2, tempo3])
```

**Преимущества:**
- Комбинирует несколько методов для более точного результата
- Медиана более устойчива к выбросам, чем среднее арифметическое

### 4. Анализ более длинного сегмента

```python
# Анализируем первые 30-60 секунд (более стабильный ритм)
# В начале трека обычно более четкий ритм
segment_length = min(sr * 60, len(y))  # Первая минута или весь трек
segment = y[:segment_length]
tempo, beats = librosa.beat.beat_track(y=segment, sr=sr)
```

**Преимущества:**
- Начало трека обычно имеет более четкий и стабильный ритм
- Избегаем влияния медленных/быстрых частей в середине трека

### 5. Использование дорожки drums (уже реализовано)

Анализ дорожки drums дает более точный результат, так как:
- Ударные имеют более четкие и регулярные паттерны
- Меньше влияния вокала и других инструментов

**Текущая реализация:**
- Если доступна дорожка drums после Demucs, она используется для анализа
- Это уже реализовано в `lib/analyzeAudio.ts`

### 6. Предобработка аудио

```python
# Усиление ритмических компонентов
# Используем высокочастотные фильтры для выделения ударных
y_harmonic, y_percussive = librosa.effects.hpss(y)
# Анализируем перкуссионную часть
tempo, beats = librosa.beat.beat_track(y=y_percussive, sr=sr)
```

**Преимущества:**
- Отделяет ритмические компоненты от гармонических
- Более четкий анализ ритма

## Почему Moises.ai может быть точнее

[Moises.ai](https://studio.moises.ai/) использует:
- **Обученные нейросети** на больших датасетах музыки
- **Понимание музыкального контекста** (не только анализ сигнала)
- **Специализированные модели** для разных жанров

Librosa работает на уровне **анализа сигнала**, без понимания музыкальной структуры.

## Рекомендации для реализации

### Вариант 1: Улучшить текущий метод (быстро)

Обновить `scripts/analyze-bpm-offset.py`:

```python
def analyze_track(audio_path, use_drums=False, drums_path=None):
    if use_drums and drums_path:
        y, sr = librosa.load(drums_path)
    else:
        y, sr = librosa.load(audio_path)
    
    # Улучшенный метод: комбинирование нескольких подходов
    # Метод 1: beat_track с оптимизированными параметрами
    tempo1, _ = librosa.beat.beat_track(
        y=y, sr=sr,
        start_bpm=120.0,
        std_bpm=1.0,
        trim=True
    )
    
    # Метод 2: tempogram
    tempo2 = librosa.beat.tempo(y=y, sr=sr, aggregate=np.median)[0]
    
    # Усредняем (медиана более устойчива)
    bpm = round(np.median([tempo1[0], tempo2]))
    
    # ... остальной код для offset
```

### Вариант 2: Полная реализация (более точно)

1. Комбинировать 3-4 метода
2. Использовать предобработку (hpss)
3. Анализировать несколько сегментов
4. Усреднять результаты с весами

### Вариант 3: Ручная корректировка (самый точный)

Добавить в админ-панель возможность:
- Прослушать трек
- Увидеть автоматически определенный BPM
- Скорректировать вручную при необходимости

## Следующие шаги

1. ✅ Текущая реализация работает (точность ±2-3 BPM)
2. ⏳ Улучшить метод в `analyze-bpm-offset.py` (Вариант 1)
3. ⏳ Добавить ручную корректировку в админ-панели
4. ⏳ Тестирование на реальных треках бачаты

## Примечания

- Для большинства случаев текущая точность **достаточна**
- Если нужна точность как у Moises.ai, стоит рассмотреть:
  - Использование обученных моделей (более сложно)
  - Ручную корректировку (проще и надежнее)
  - Комбинирование автоматического определения + ручной проверки

